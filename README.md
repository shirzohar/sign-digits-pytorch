# ğŸ§  Sign Language Digits Classification (PyTorch)

## ğŸ“Œ Overview
This project implements a deep learning solution using **fully connected neural networks (FCNN)** in **PyTorch** to classify hand signs representing digits 0â€“9, based on the **Sign Language Digits Dataset**. The project was done as part of a mid-semester milestone in the "Basics of Deep Learning" course.

The project includes:
- âœ… **Binary classification** â€“ distinguish between two specific digits ("4" vs. "5").
- âœ… **Multi-class classification** â€“ recognize all ten digits (0â€“9).
- âœ… Architecture & hyperparameter experiments.

---

## ğŸ“‚ Files
```
sign-language-classification/
â”œâ”€â”€ basics_2025.ipynb   # Main Colab notebook
â”œâ”€â”€ report.pdf          # Final project report
â”œâ”€â”€ README.md                               # Project overview and usage
â”œâ”€â”€ requirements.txt                        # Python dependencies
```

---

## ğŸ“Š Dataset
- **Name:** Sign Language Digits Dataset
- **Size:** 5,000 grayscale images (28x28 pixels)
- **Classes:** Digits 0â€“9
- **Preprocessing:**
  - Normalized pixel values to [0, 1]
  - Flattened images to 784-dim vectors
  - Relabeled subset for binary classification (4 â†’ 0, 5 â†’ 1)
  - Split into train (80%), val (10%), test (10%)

---

## ğŸ—ï¸ Model Architectures
### ğŸ”¹ Binary Classification Model
- Input: 784 neurons
- Hidden layers: [128 â†’ 64], activation: ReLU
- Output: 1 neuron, activation: Sigmoid
- Loss: `BCELoss`
- Accuracy: **92.8%** (Test)

### ğŸ”¹ Base Model (Multi-class)
- Input: 784 neurons
- Hidden layers: [128 â†’ 64], ReLU + Dropout(0.2)
- Output: 10 neurons, activation: Log-Softmax
- Loss: `CrossEntropyLoss`
- Accuracy: **45.4%** (Test)

### ğŸ”¹ Experiment 1: Deeper Network
- Hidden layers: [512 â†’ 256 â†’ 128], ReLU
- Accuracy: **97.1%** (Test)

### ğŸ”¹ Experiment 2: Hyperparameter Tuning
- Optimizer: SGD
- LR: 0.01, Batch Size: 64, Dropout: 0.3
- Accuracy: **99.0%** (Test)

---

## ğŸ“ˆ Evaluation Metrics
- Accuracy (Train, Validation, Test)
- Confusion Matrix
- Classification Report (Precision, Recall, F1)
- Training & Validation Loss / Accuracy graphs

---

## ğŸš€ Run Instructions
1. Clone repository or open the notebook in **Google Colab**
2. Ensure dataset `.npy` files are available in your environment
3. Run notebook cells sequentially:
   - Data loading & preprocessing
   - Model training
   - Evaluation & visualization

---

## ğŸ† Final Results
| Model              | Test Accuracy | Train Acc | Val Acc |
|-------------------|---------------|-----------|---------|
| Base Model        | 45.4%         | 45.7%     | 45.9%   |
| Experiment 1      | 97.1%         | 98.9%     | 97.0%   |
| Experiment 2 â­    | **99.0%**     | 99.5%     | 98.8%   |

---

## ğŸ‘¥ Authors
- **Shir Zohar**  
- **Sivan Zagdon**

---

## ğŸ“œ License
This project is for academic use as part of the Deep Learning course @ Colman College.
